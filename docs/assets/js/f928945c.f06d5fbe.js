"use strict";(self.webpackChunkstreamsheets=self.webpackChunkstreamsheets||[]).push([[88069],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>c});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),u=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},p=function(e){var t=u(e.components);return a.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),d=u(n),c=o,h=d["".concat(s,".").concat(c)]||d[c]||m[c]||i;return n?a.createElement(h,r(r({ref:t},p),{},{components:n})):a.createElement(h,r({ref:t},p))}));function c(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,r=new Array(i);r[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:o,r[1]=l;for(var u=2;u<i;u++)r[u]=n[u];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},25131:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>k,contentTitle:()=>c,default:()=>g,frontMatter:()=>d,metadata:()=>h,toc:()=>f});var a=n(3905),o=Object.defineProperty,i=Object.defineProperties,r=Object.getOwnPropertyDescriptors,l=Object.getOwnPropertySymbols,s=Object.prototype.hasOwnProperty,u=Object.prototype.propertyIsEnumerable,p=(e,t,n)=>t in e?o(e,t,{enumerable:!0,configurable:!0,writable:!0,value:n}):e[t]=n,m=(e,t)=>{for(var n in t||(t={}))s.call(t,n)&&p(e,n,t[n]);if(l)for(var n of l(t))u.call(t,n)&&p(e,n,t[n]);return e};const d={id:"high-availability-openshift",title:"High Availability Openshift",sidebar_label:"HA Openshift"},c=void 0,h={unversionedId:"openshift/high-availability-openshift",id:"openshift/high-availability-openshift",title:"High Availability Openshift",description:"To set up a multi-node-HA Mosquitto broker and Management Center with autoscaling  using Helm charts, you'll first need a  running Openshift OKD cluster. Openshift offers lot of different features on top of Kubernetes. For details on Openshift and OKD you can refer to the Introduction page. For deploying a full fledged OKD cluster,  you can follow the official Openshift OKD installation documentation.  OKD can be mainly installed in two different fashion:",source:"@site/mosquitto/openshift/high-availability-openshift.md",sourceDirName:"openshift",slug:"/openshift/high-availability-openshift",permalink:"/documentation-staging/mosquitto/next/openshift/high-availability-openshift",draft:!1,tags:[],version:"current",frontMatter:{id:"high-availability-openshift",title:"High Availability Openshift",sidebar_label:"HA Openshift"},sidebar:"someSidebar",previous:{title:"Introduction",permalink:"/documentation-staging/mosquitto/next/openshift/introduction"},next:{title:"HA-Autoscaling Openshift",permalink:"/documentation-staging/mosquitto/next/openshift/high-availability-autoscaling-openshift"}},k={},f=[{value:"Openshift Cluster Setup and Configuration",id:"openshift-cluster-setup-and-configuration",level:2},{value:"Dependencies and Prerequisites",id:"dependencies-and-prerequisites",level:3},{value:"Installation",id:"installation",level:2},{value:"Installation using Helm Charts:",id:"installation-using-helm-charts",level:3},{value:"Further Useful Commands:",id:"further-useful-commands",level:3},{value:"Installation using Openshift UI",id:"installation-using-openshift-ui",level:3},{value:"Usage",id:"usage",level:2}],N={toc:f};function g(e){var t,o=e,{components:p}=o,d=((e,t)=>{var n={};for(var a in e)s.call(e,a)&&t.indexOf(a)<0&&(n[a]=e[a]);if(null!=e&&l)for(var a of l(e))t.indexOf(a)<0&&u.call(e,a)&&(n[a]=e[a]);return n})(o,["components"]);return(0,a.kt)("wrapper",(t=m(m({},N),d),i(t,r({components:p,mdxType:"MDXLayout"}))),(0,a.kt)("p",null,"To set up a multi-node-HA Mosquitto broker and Management Center with autoscaling  using Helm charts, you'll first need a  running Openshift OKD cluster. Openshift offers lot of different features on top of Kubernetes. For details on Openshift and OKD you can refer to the Introduction page. For deploying a full fledged OKD cluster,  you can follow the official Openshift OKD installation ",(0,a.kt)("a",m({parentName:"p"},{href:"https://docs.okd.io/"}),"documentation"),".  OKD can be mainly installed in two different fashion:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"IPI: Installer Provisioned Infrastructure"),(0,a.kt)("li",{parentName:"ol"},"UPI: User Provisioned Infrastructure")),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Installer Provisioned Infrastructure:"),"  Installer Provisioned Infrastructure (IPI) in OKD/OpenShift refers to a deployment model where the installation program provisions and manages all the components of the infrastructure needed to run the OpenShift cluster. This includes the creation of virtual machines, networking rules, load balancers, and storage components, among others. The installer uses cloud-specific APIs to automatically set up the infrastructure, making the process faster, more standardized, and less prone to human error compared to manually setting up the environment."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"User Provisioned Infrastructure:"),"  User Provisioned Infrastructure (UPI) in OKD/OpenShift is a deployment model where users manually create and manage all the infrastructure components required to run the OpenShift cluster. This includes setting up virtual machines or physical servers, configuring networking, load balancers, storage, and any other necessary infrastructure components. Unlike the Installer Provisioned Infrastructure (IPI) model, where the installation program automatically creates and configures the infrastructure, UPI offers users complete control over the deployment process."),(0,a.kt)("p",null,"You are free to choose your own method among the two. You can also choose the cloud provider you want to deploy your solution on. Openshift OKD supports number of different cloud providers and also gives you an option to do bare-metal installation. In this deployment we went forward with UPI and deployed our infrastructure on Google Cloud Platform (GCP) using the ",(0,a.kt)("inlineCode",{parentName:"p"},"Private cluster")," method mentioned ",(0,a.kt)("a",m({parentName:"p"},{href:"https://docs.okd.io/latest/installing/installing_gcp/installing-gcp-private.html"}),"here"),". Therefore, this solution is developed and tested on GCP, however it is unlikely that basic infrastructure would differ across different cloud providers."),(0,a.kt)("p",null,"A ",(0,a.kt)("inlineCode",{parentName:"p"},"private cluster")," in GCP ensures that the nodes are isolated in a private network, reducing exposure to the public internet but again you are free to choose your own version of infrastructure supported by Openshift OKD.  We will briefly discuss how the infrastructure looks like in our case so that you can have a reference for your own infrastructure."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"OKD Infrastructure (During provisioning)",src:n(1515).Z,title:"OKD Infrastructure on GCP during provisioning",width:"751",height:"510"})),(0,a.kt)("p",null,"Figure 1: OKD Infrastructure on GCP during provisioning"),(0,a.kt)("p",null,"The diagram depicts the deployment process for our OCP cluster on GCP, starting with the establishment of a bastion host. Bastion host is where we'll execute commands to configure the bootstrap node, then the Master nodes, and finally, the worker nodes in a separate subnet. Before initiating the bootstrap procedure, we set up the essential infrastructure components, including networks, subnetworks, an IAM service account, an IAM project, a Private DNS zone, Load balancers, Cloud NATs, and a Cloud Router."),(0,a.kt)("p",null,"Upon completing the bootstrap phase, we dismantled the bootstrap components from the cluster. Subsequently, we focussed on creating the worker nodes. After the worker nodes are operational, we set up a reverse proxy on the bastion host to facilitate local access to the OCP Console UI through our browser. To conclude, we confirm that all cluster operators are marked as \u2018Available\u2019. Once we done with the provisioning the architecture would look something like Figure 2. More detailed steps can be found in the official documentation.  These discussed steps are all part of the official  ",(0,a.kt)("a",m({parentName:"p"},{href:"https://docs.okd.io/latest/installing/installing_gcp/installing-gcp-private.html"}),"documentation"),"."),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"OKD Infrastructure (Post provisioning)",src:n(82081).Z,title:"OKD Infrastructure on GCP post provisioning ",width:"684",height:"676"})),(0,a.kt)("p",null,"Figure 2: OKD Infrastructure on GCP post provisioning"),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"Note:")," This deployment involves setting up a private cluster, which means access to the cluster is limited to through the bastion host. Consequently, we avoid using public DNS for this installation, relying solely on a private DNS zone. To facilitate access to the external UI, we will employ a reverse proxy for this purpose."),(0,a.kt)("p",null,"We will also provision a NFS server in the same subnet as worker node. Therefore, this  setup would deploy a 3 Mosquitto broker as a statefulsets, a Management-Center pod and HA-proxy pod as a deployment entity.  These statefulsets and deployment pods would mount volumes from the NFS server.  You would need to setup the NFS server before using this deployment."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Recommended Setup")),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"3 Control-plane node, 2 worker nodes and a NFS Server"),(0,a.kt)("li",{parentName:"ol"},"Management center (MMC) is configured to have a node affinity that means the pod for MMC will spawn on a specific worker node. The default configuration expects names of the worker  nodes to be ",(0,a.kt)("inlineCode",{parentName:"li"},"openshift-test-rcjp5-worker-0")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"openshift-test-rcjp5-worker-1"),". Given the nodes are named in similar fashion, MMC would be spawned on ",(0,a.kt)("inlineCode",{parentName:"li"},"openshift-test-rcjp5-worker-0"),"."),(0,a.kt)("li",{parentName:"ol"},"If you want to have different names for your nodes you can also do that. You will have to adjust the hostnames of nodes in helm chart so that the MMC node affinity remains intact. To adjust the helm chart you will have to uncompress the helm charts and change the hostnames entries of ",(0,a.kt)("inlineCode",{parentName:"li"},"values.yaml"),". You can do so using the following command:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"tar -xzvf mosquitto-multi-node-multi-host-0.1.0.tgz")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"cd mosquitto-multi-node-multi-host")),(0,a.kt)("li",{parentName:"ul"},"Change the values of hostname from ",(0,a.kt)("inlineCode",{parentName:"li"},"openshift-test-rcjp5-worker-0/openshift-test-rcjp5-worker-1"),"  to the names of your machines. For eg, ",(0,a.kt)("inlineCode",{parentName:"li"},"openshift-test-rcjp5-worker-0")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"openshift-test-rcjp5-worker-1")," can be renamed as ",(0,a.kt)("inlineCode",{parentName:"li"},"worker-node-0")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"worker-node-1"),". Doing this, MMC would now be spawned on the node named ",(0,a.kt)("inlineCode",{parentName:"li"},"worker-node-0"),"."),(0,a.kt)("li",{parentName:"ul"},"Go back to the parent directory:\n",(0,a.kt)("inlineCode",{parentName:"li"},"cd ../")),(0,a.kt)("li",{parentName:"ul"},"Package the helm chart to its original form using:\n",(0,a.kt)("inlineCode",{parentName:"li"},"helm package mosquitto-multi-node-multi-host"))))),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"HA-PROXY Configurations"),"\nHA-proxy need to be configured accordingly for the kubernetes setup. For eg:  server m1, m2 and m3 needs to be configured in this case. Instead of using docker IP we would use DNS names to address the pods. For eg\n",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-0.mosquitto.multinode.svc.cluster.local"),". Here ",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-0"),",",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-1"),",",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-2")," are the name of individual mosquitto pods running as statefulsets. Each new pod would increase its pod-ordinal by 1. Rest can be defined as follows\n",(0,a.kt)("inlineCode",{parentName:"p"},"<pod-name>.<name-of-the-statefulset>.<namespace>.svc.cluster.local")),(0,a.kt)("p",null,'Your setup folder comes along with a default configuration of haproxy config which is given below. This assumes that your using namespace name as "multinode". You can also change the namespace name if you want and the procedure to do it would be discussed at a later stage.'),(0,a.kt)("pre",null,(0,a.kt)("code",m({parentName:"pre"},{}),"global\n    daemon\n    maxconn 4096\n\nfrontend mqtt_frontend\n    bind *:1883\n    mode tcp\n    default_backend mqtt_backend\n    timeout client 10m\n\nbackend mqtt_backend\n    timeout connect 5000\n    timeout server 10m\n    mode tcp\n    option redispatch\n    server m1 mosquitto-0.mosquitto.multinode.svc.cluster.local:1883 check on-marked-down shutdown-sessions\n    server m2 mosquitto-1.mosquitto.multinode.svc.cluster.local:1883 check on-marked-down shutdown-sessions\n    server m3 mosquitto-2.mosquitto.multinode.svc.cluster.local:1883 check on-marked-down shutdown-sessions\n")),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"Note"),": Make sure to add more entries to this haproxy.cfg file if you wish to add nodes to this cluster. You would have to reconfigure the HACONFIG in that case. You can refer to ",(0,a.kt)("inlineCode",{parentName:"p"},"Add Node")," i.e point 7 in Installation section for tips on reconfiguring haconfig configmap."),(0,a.kt)("h2",m({},{id:"openshift-cluster-setup-and-configuration"}),"Openshift Cluster Setup and Configuration"),(0,a.kt)("h3",m({},{id:"dependencies-and-prerequisites"}),"Dependencies and Prerequisites"),(0,a.kt)("p",null,"As we chose to use a private cluster, therefore master and worker nodes would not have access to the internet. Therefore, we will install the dependencies on the bastion node and would also deploy the application from the bastion node."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Prerequisites")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Running Openshift OKD cluster by following the official documentation guide of ",(0,a.kt)("a",m({parentName:"li"},{href:"https://docs.okd.io/"}),"Openshift")),(0,a.kt)("li",{parentName:"ul"},"Helm"),(0,a.kt)("li",{parentName:"ul"},"Bastion node with internet access (running Ubuntu in the example case).")),(0,a.kt)("p",null,"After checking the environment prerequisites are set, follow we will prepare the Mosquitto environment:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Setup the ha-cluster setups folder:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Copy or setup the ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift")," folder to the Bastion node. Also make sure to create a directory inside the copied folder on Bastion node named ",(0,a.kt)("inlineCode",{parentName:"li"},"license")," that contains the ",(0,a.kt)("inlineCode",{parentName:"li"},"license.lic")," file we provided you. So the relative path would be ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/license/license.lic"),"."))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Choose Architecture Folder:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Depending on your host architecture, navigate to the corresponding folder:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"For Debian AMD64:",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",m({parentName:"pre"},{className:"language-bash"}),"cd mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/kubernetes/multi-node-multi-host/debian_amd64\n"))))))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Setup Kubernetes: IMPORTANT")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Execute the setup script to configure Kubernetes:",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",m({parentName:"pre"},{className:"language-bash"}),"bash setup.sh\n")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Follow the instructions of this file. This would create configmap for mosquitto.conf, create configmaps for your license file."),(0,a.kt)("li",{parentName:"ul"},"Make sure you have placed your license file in the required folder before running this script i.e at ",(0,a.kt)("inlineCode",{parentName:"li"},"/home/<user>/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/license/license.lic")," (if license folder does not exist ,create it and add your license.lic file)"),(0,a.kt)("li",{parentName:"ul"},"The script automatically detects the path where the ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift")," folder resides on the Bastion node. If the auto-detected path is not correct, script also prompts you to enter the correct path."),(0,a.kt)("li",{parentName:"ul"},"The default namespace for installation is ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode"),". You can change the namespace through the setup script. Script will prompt you to choose the namespace of your choice. It also configures the haconfig file with the updated namespace."))))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Setup Kubernetes Secrets:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"This step is required for OKD to pull required docker images from the registry. The credentials ",(0,a.kt)("inlineCode",{parentName:"li"},"docker-username")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"docker-password")," would be provided to you by the Cedalo team. You can set the secrets using the following command::",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",m({parentName:"pre"},{className:"language-bash"}),"oc create secret docker-registry  mosquitto-pro-secret  --docker-server=registry.cedalo.com --docker-username=<username> --docker-password=<password>  --docker-email=<email> -n <namespace>\n"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"namespace"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"namespace")," should be the same as the one you selected or enetered while running the ",(0,a.kt)("inlineCode",{parentName:"li"},"setup.sh"),"."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"docker-username"),": Your docker username"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"docker-password"),": Your docker password"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"docker-email"),": Email registered for accessing docker registry"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Setup NFS Server")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Copy or setup the ",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift")," folder to the NFS-Server.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Install necessary dependencies\n",(0,a.kt)("inlineCode",{parentName:"p"},"sudo apt-get update"),"\n",(0,a.kt)("inlineCode",{parentName:"p"},"sudo apt-get install nfs-kernel-server"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Configure exports directory.Open the ",(0,a.kt)("inlineCode",{parentName:"p"},"/etc/exports")," file on NFS-server. Expose the directories so that pods running on other worker nodes can access these directories and mount the volumes."),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"The default starting point of the cluster is with 3 Mosquitto broker nodes, however we will configure and expose a total of 6 Mosquitto data directories along with a MMC config directory in the NFS server. As the provisioning of data directories on the NFS servers are not dynamic at the moment, configuring three extra Mosquitto data directories makes the job easier later when you want to add further nodes."),(0,a.kt)("li",{parentName:"ul"},"The helm charts therefore is also configured in a fashion that they create total of 7 persistent volumes and persistent volume claims (6 for Mosquitto data directories and 1 for MMC). However, only three Mosquitto broker would be spinned up by default."),(0,a.kt)("li",{parentName:"ul"},"You can use the following as a reference. Here we expose six Mosquitto nodes and management center.",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",m({parentName:"pre"},{}),"/root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server1/mosquitto/data *(rw,sync,no_root_squash,no_subtree_check)\n/root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server2/mosquitto/data  *(rw,sync,no_root_squash,no_subtree_check)\n/root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server3/mosquitto/data *(rw,sync,no_root_squash,no_subtree_check)\n/root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server4/mosquitto/data *(rw,sync,no_root_squash,no_subtree_check)\n/root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server5/mosquitto/data *(rw,sync,no_root_squash,no_subtree_check)\n/root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server6/mosquitto/data *(rw,sync,no_root_squash,no_subtree_check)\n/root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server1/management-center/config *(rw,sync,no_root_squash,no_subtree_check)\n"))))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"On your bastion node"),": Check the allocated user id for your namespace after you finished running ",(0,a.kt)("inlineCode",{parentName:"p"},"setup.sh")," and configured the namespace and configmaps. You can check the allocated user id for your namespace by running the command ",(0,a.kt)("inlineCode",{parentName:"p"},"oc describe namespace <namespace>")," where ",(0,a.kt)("inlineCode",{parentName:"p"},"<namespace>")," is the namespace you chose while running ",(0,a.kt)("inlineCode",{parentName:"p"},"setup.sh"),". For default namespace i.e ",(0,a.kt)("inlineCode",{parentName:"p"},"multinode"),", the command would be ",(0,a.kt)("inlineCode",{parentName:"p"},"oc describe namespace multinode"),"."),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"The above command would output a response. A sample output could be like:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",m({parentName:"pre"},{}),"Name:         multinode\nLabels:       kubernetes.io/metadata.name=multinode\n              pod-security.kubernetes.io/audit=restricted\n              pod-security.kubernetes.io/audit-version=v1.24\n              pod-security.kubernetes.io/warn=restricted\n              pod-security.kubernetes.io/warn-version=v1.24\nAnnotations:  openshift.io/sa.scc.mcs: s0:c27,c4\n              openshift.io/sa.scc.supplemental-groups: 1000710000/10000\n              openshift.io/sa.scc.uid-range: 1000710000/10000\nStatus:       Active\n\nNo resource quota.\nNo LimitRange resource.\n"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Note down the value for ",(0,a.kt)("inlineCode",{parentName:"p"},"openshift.io/sa.scc.uid-range"),". In this is case it is ",(0,a.kt)("inlineCode",{parentName:"p"},"1000710000"),". You would need these to give permissions to the exposed directories in NFS server and also while installing the helm chart.")))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"The noted user id will now be used to make sure all the ",(0,a.kt)("inlineCode",{parentName:"p"},"data")," directories have adequate privileges. This confirms that Mosquitto Kubernetes pods can create additional directories inside these ",(0,a.kt)("inlineCode",{parentName:"p"},"data")," directories. Therefore, we will now give adequate permission using the user id we noted in the previous step to all the relevant ",(0,a.kt)("inlineCode",{parentName:"p"},"data")," directories of Mosquitto server and ",(0,a.kt)("inlineCode",{parentName:"p"},"config")," directory of MMC using following command:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",m({parentName:"pre"},{}),"sudo chown -R 1000710000:1000710000 /root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server1/mosquitto/data\nsudo chown -R 1000710000:1000710000 /root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server2/mosquitto/data\nsudo chown -R 1000710000:1000710000 /root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server3/mosquitto/data\nsudo chown -R 1000710000:1000710000 /root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server4/mosquitto/data\nsudo chown -R 1000710000:1000710000 /root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server5/mosquitto/data\nsudo chown -R 1000710000:1000710000 /root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server6/mosquitto/data\nsudo chown -R 1000710000:1000710000 /root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/server1/management-center/config\n")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Note"),": We provide ownership of ",(0,a.kt)("inlineCode",{parentName:"li"},"1000710000")," based on uid range of our namespace. Please note down and use the uid range of your own namespace from the previous step."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Expose the directories using:\n",(0,a.kt)("inlineCode",{parentName:"p"},"sudo exportfs -a"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"Restart the kernel-server\n",(0,a.kt)("inlineCode",{parentName:"p"},"sudo systemctl restart nfs-kernel-server")))))),(0,a.kt)("h2",m({},{id:"installation"}),"Installation"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Prerequisites"),":"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Openshift OKD Cluster should be up and running."),(0,a.kt)("li",{parentName:"ol"},"You have successfully run setup.sh file, leading to successful creation of configmaps namely haconfig, mosquitto-license and mosquitto-config1.")),(0,a.kt)("p",null,"Once cluster is up and running and you have installed all the configmaps through ",(0,a.kt)("inlineCode",{parentName:"p"},"setup.sh"),", you can proceed to deploying the Mosquitto application."),(0,a.kt)("p",null,"We can deploy our Mosquitto application on openshift using two different strategies:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",m({parentName:"li"},{href:"#installation-using-helm-charts"}),"Installation using Helm Charts")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",m({parentName:"li"},{href:"#installation-using-openshift-ui"}),"Installation using Openshift UI"))),(0,a.kt)("h3",m({},{id:"installation-using-helm-charts"}),"Installation using Helm Charts:"),(0,a.kt)("p",null,"Helm charts offer a comprehensive solution for configuring various Kubernetes resources\u2014including stateful sets, deployment templates, services, and service accounts\u2014through a single command, streamlining the deployment process."),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Setup the folder on your Bastion Node:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Make sure you have the ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift")," folder on the Bastion-node."))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Change Directory:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Navigate to the project directory (i.e multi-node-multi-host).\n",(0,a.kt)("inlineCode",{parentName:"li"},"cd mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/kubernetes/multi-node-multi-host/")))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Install Helm Chart:")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Use the following ",(0,a.kt)("inlineCode",{parentName:"li"},"helm install")," command to deploy the Mosquitto application on to your OKD cluster. Replace ",(0,a.kt)("inlineCode",{parentName:"li"},"<release-name>")," with the desired name for your Helm release and ",(0,a.kt)("inlineCode",{parentName:"li"},"<namespace>")," with your chosen Kubernetes namespace:",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",m({parentName:"pre"},{className:"language-bash"}),"helm install <release-name>  mosquitto-multi-node-multi-host-0.1.0.tgz   --set repoPath=<root-path-to-openshift-folder> --set runAsUser=<namespace-alloted-user-id> --set nfs=<your-nfs-ip> -n <namespace>\n"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"repoPath"),": Set the ",(0,a.kt)("inlineCode",{parentName:"li"},"repoPath")," flag to the path where the folder ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift")," resides on NFS server. In our case it exists on ",(0,a.kt)("inlineCode",{parentName:"li"},"/root/mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift"),"  therefore the ",(0,a.kt)("inlineCode",{parentName:"li"},"repoPath")," would be ",(0,a.kt)("inlineCode",{parentName:"li"},"/root"),"."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"namespace"),": Set it to the namespace of your deployment."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"namespace-alloted-user-id"),": Set it to user id you noted while setting up the NFS server."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Note"),": If you want to deploy the setup in a different namespace other than ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode"),", make sure to pass a separate flag ",(0,a.kt)("inlineCode",{parentName:"li"},"--set namespace=<your-custom-namespace>")," along with the helm installation command. This custom namespace must have been created while using ",(0,a.kt)("inlineCode",{parentName:"li"},"setup.sh")," file."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"Note"),": You need to configure the IP of your NFS server by passing ",(0,a.kt)("inlineCode",{parentName:"li"},"--set nfs=<your-nfs-ip>")," by passing it along with helm installation command."),(0,a.kt)("li",{parentName:"ul"},"So for eg: If you NFS IP is ",(0,a.kt)("inlineCode",{parentName:"li"},"10.10.10.10"),",your user id for your namespace is ",(0,a.kt)("inlineCode",{parentName:"li"},"1000710000"),", mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift resides at the location  ",(0,a.kt)("inlineCode",{parentName:"li"},"/root")," on your nfs,  your name namespace is ",(0,a.kt)("inlineCode",{parentName:"li"},"test-namespace")," and your arbitrary release name is ",(0,a.kt)("inlineCode",{parentName:"li"},"sample-release-name")," then your helm installation command should be:",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",m({parentName:"pre"},{className:"language-bash"}),"   helm install sample-release-name  mosquitto-multi-node-multi-host-0.1.0.tgz   --set repoPath=/root  --set runAsUser=1000710000 -n test-namespace --set namespace=test-namespace --set nfs=10.10.10.10\n"))))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"You can monitor the running pods using the following command:\n",(0,a.kt)("inlineCode",{parentName:"p"},"oc get pods -o wide -n <namespace>"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"To access MMC and HAproxy connection over the internet, you can add an additional HAproxy service on Bastion node that would redirect traffic to your worker node which is running MMC and Haproxy(would again direct the traffic to mosquitto brokers) pods . This is because the worker nodes do not have access over the internet.  Below is an example how you can add extra frontend and backend to forward traffic to MMC and HA."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",m({parentName:"pre"},{}),"frontend localhost_31021\n    bind *:31021\n    option tcplog\n    mode tcp\n    default_backend servers_w0\n\nbackend servers_w0\n    mode tcp\n    server w0 10.1.20.2:31021\n\nfrontend localhost_31028\n    bind *:31028\n    option tcplog\n    mode tcp\n    default_backend servers_w1\n\nbackend servers_w1\n    mode tcp\n    server w1 10.1.20.2:31028  # Assuming 10.1.20.3 is the IP of server w1\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"You can then access the MMC console using external public ip of your bastion node on port 31021. Open using below url on your browser:\n",(0,a.kt)("inlineCode",{parentName:"p"},"http://<external-public-ip-of-bastion-node>:31021")," (MMC)")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Configure your Cluster on MMC")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Navigate to ",(0,a.kt)("inlineCode",{parentName:"li"},"Cluster Management")," and click ",(0,a.kt)("inlineCode",{parentName:"li"},"NEW CLUSTER"),"."),(0,a.kt)("li",{parentName:"ul"},"Configure ",(0,a.kt)("inlineCode",{parentName:"li"},"Name"),", ",(0,a.kt)("inlineCode",{parentName:"li"},"Description")," and choose between ",(0,a.kt)("inlineCode",{parentName:"li"},"Full-sync")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"Dynamic Security Sync"),"."),(0,a.kt)("li",{parentName:"ul"},"Configure IP address: Instead of private IP address we will DNS address.",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",m({parentName:"pre"},{}),"- For node1: `mosquitto-1.mosquitto.multinode.svc.cluster.local` and select broker2 from drop-down\n- For node2: `mosquitto-2.mosquitto.multinode.svc.cluster.local` and select broker2 from drop-down\n- For node3: `mosquitto-3.mosquitto.multinode.svc.cluster.local` and select broker3 from drop-down\n-  Replace multinode with your own namespace. If you have used the default one, use the mentioned configurations.\n"))),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Save")))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Connect mosquitto brokers and subscribe onto all System topic: ",(0,a.kt)("inlineCode",{parentName:"p"},"mosquitto_sub -h <external-public-ip-of-bastion-node> -p 30128 -u <username> -P <password> -t '$SYS/#'"),". Make sure to replace your IP, username and password")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"To uninstall the setup:\n",(0,a.kt)("inlineCode",{parentName:"p"},"helm uninstall <release-name> -n <namespace>"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Add Nodes")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Configure your HA-proxy by adding entries to the haproxy.cfg.For eg to add fourth node, add below line to haproxy.cfg:\n",(0,a.kt)("inlineCode",{parentName:"li"},"server m4 mosquitto-3.mosquitto.multinode.svc.cluster.local:1883 check on-marked-down shutdown-sessions")),(0,a.kt)("li",{parentName:"ul"},"Delete the haproxy configmap of kubernetes\n",(0,a.kt)("inlineCode",{parentName:"li"},"oc delete configmap haconfig -n <namespace>")),(0,a.kt)("li",{parentName:"ul"},"Reconfigure HAconfig:\n",(0,a.kt)("inlineCode",{parentName:"li"},"oc create configmap haconfig -n <namespace> --from-file=<path-to-haproxy.cfg>")),(0,a.kt)("li",{parentName:"ul"},"Uninstall helm package\n",(0,a.kt)("inlineCode",{parentName:"li"},"helm uninstall <release-name> -n <namespace>")),(0,a.kt)("li",{parentName:"ul"},"We do not need to configure extra data directories in the NFS server till we exceed the count of 6 mosquitto brokers as we already addressed this while configuring our NFS server."),(0,a.kt)("li",{parentName:"ul"},"Reinstall helm package so that new configmaps can come into effect(Use the same command you used to install it the first time with appropriate flags. Below command eg is just a reference)\n",(0,a.kt)("inlineCode",{parentName:"li"},"helm install <release-name>  mosquitto-multi-node-multi-host-0.1.0.tgz   --set repoPath=$HOME -n <namespace>")),(0,a.kt)("li",{parentName:"ul"},"In order to add nodes to existing cluster, you can scale the kubernetes replica count of statefulset to desired number. For eg if you want to increase the number of nodes from default three nodes to five nodes you can use the following command:\n",(0,a.kt)("inlineCode",{parentName:"li"}," oc scale statefulsets mosquitto --replicas=5 -n <namespace>")),(0,a.kt)("li",{parentName:"ul"},"You can now add the broker connections and the additional nodes in the cluster through Management-center.",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Open your MMC, navigate to broker connections, click on ",(0,a.kt)("inlineCode",{parentName:"li"},"NEW CONNECTION")," ."),(0,a.kt)("li",{parentName:"ul"},"Fill in the details like ",(0,a.kt)("inlineCode",{parentName:"li"},"ID"),"(make sure it does not conflict with the existing ones), ",(0,a.kt)("inlineCode",{parentName:"li"},"NAME"),": name of the connection (you can choose your own name)."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"URL"),": ",(0,a.kt)("inlineCode",{parentName:"li"},"mqtt://mosquitto-x.mosquitto.<namespace>.svc.cluster.local:1885"),"  . Replace ",(0,a.kt)("inlineCode",{parentName:"li"},"x")," in ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-x")," with a valid number based on the which node you are adding. If you are adding a fourth node and the name of your namespace is  ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," then the entry would be ",(0,a.kt)("inlineCode",{parentName:"li"},"mqtt://mosquitto-3.mosquitto.multinode.svc.cluster.local:1885"),"."),(0,a.kt)("li",{parentName:"ul"},"Add your username and password given by the cedalo team, select/deselect further options and click ",(0,a.kt)("inlineCode",{parentName:"li"},"CONNECT & SAVE"),"."))),(0,a.kt)("li",{parentName:"ul"},"Adding new node to existing cluster:",(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Navigate to ",(0,a.kt)("inlineCode",{parentName:"li"},"Cluster Management")," and select your existing cluster."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Edit")," and select ",(0,a.kt)("inlineCode",{parentName:"li"},"Add Node"),"."),(0,a.kt)("li",{parentName:"ul"},"Enter DNS address in IP address field.  For eg ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-x.mosquitto.<namespace>.svc.cluster.local"),". Replace ",(0,a.kt)("inlineCode",{parentName:"li"},"x")," in ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-x")," with a valid number based on the which node you are adding. If you are adding a fourth node and the name of your namespace is  ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," then the entry would be ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-3.mosquitto.multinode.svc.cluster.local"),"."),(0,a.kt)("li",{parentName:"ul"},"Select ",(0,a.kt)("inlineCode",{parentName:"li"},"Add Node")," and  click ",(0,a.kt)("inlineCode",{parentName:"li"},"Save"),"."))))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Remove Nodes")),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"You can start by removing the node configuration from the existing cluster using the Management Center."),(0,a.kt)("li",{parentName:"ul"},"You can now remove the broker connections using the Management Center."),(0,a.kt)("li",{parentName:"ul"},"Then you can set the replica count to desired number. For eg if you want to decrease the number of nodes from five nodes to three nodes you can use the following command.\n",(0,a.kt)("inlineCode",{parentName:"li"}," oc  scale statefulsets mosquitto --replicas=3 -n <namespace>"))))),(0,a.kt)("h3",m({},{id:"further-useful-commands"}),"Further Useful Commands:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"If you want to change mosquitto.conf. Make the required changes in mosquitto.conf then delete the configmap and create a new one. Make sure to uninstall the deployment before making the change."),(0,a.kt)("li",{parentName:"ul"},"You can uninstall the setup using the following command:\n",(0,a.kt)("inlineCode",{parentName:"li"},"helm uninstall <release-name> -n <namespace>")),(0,a.kt)("li",{parentName:"ul"},"To delete the configmap:\n",(0,a.kt)("inlineCode",{parentName:"li"},"oc delete configmap mosquitto-config1 -n <namespace>")),(0,a.kt)("li",{parentName:"ul"},"To reconfigure the configmap:\n",(0,a.kt)("inlineCode",{parentName:"li"},"oc create configmap mosquitto-config1  -n $namespace --from-file=<path-to-mosquitto.conf>")),(0,a.kt)("li",{parentName:"ul"},"If you want to customize the deployments, you can unzip the package using:\n",(0,a.kt)("inlineCode",{parentName:"li"},"tar -xzvf mosquitto-multi-node-multi-host-0.1.0.tgz")),(0,a.kt)("li",{parentName:"ul"},"Make the changes and repackage the folder mosquitto-multi-node-single-host using:\n",(0,a.kt)("inlineCode",{parentName:"li"},"helm package mosquitto-multi-node-multi-host "))),(0,a.kt)("h3",m({},{id:"installation-using-openshift-ui"}),"Installation using Openshift UI"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Prerequisites"),":"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Openshift OKD Cluster should be up and running.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"You have successfully run ",(0,a.kt)("inlineCode",{parentName:"p"},"setup.sh")," file, the configmaps namely haconfig, mosquitto-license and mosquitto-config1 are successfully created.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Navigate to the project directory .\n",(0,a.kt)("inlineCode",{parentName:"p"},"cd mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift/kubernetes/multi-node-multi-host/mosquitto-multi-node-multi-host-openshift-ui/"),"\n")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Log in to your Openshift UI Console.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Deploy Service Accounts:")))),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Navigate to ",(0,a.kt)("inlineCode",{parentName:"li"},"User Management")," tab from side bar."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Service Accounts"),"."),(0,a.kt)("li",{parentName:"ul"},"Click on ",(0,a.kt)("inlineCode",{parentName:"li"},"Create ServiceAccount"),"."),(0,a.kt)("li",{parentName:"ul"},"Copy the content from ",(0,a.kt)("inlineCode",{parentName:"li"},"service_account.yaml")," file in ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-multi-node-multi-host-openshift-ui")," folder. Starting with service account named ",(0,a.kt)("inlineCode",{parentName:"li"},"ha"),"."),(0,a.kt)("li",{parentName:"ul"},"Paste the content and  make sure to change your namespace from ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," to your chosen namespace. (you can leave it as it is if it is default one)."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"create"),"."),(0,a.kt)("li",{parentName:"ul"},"Repeat the steps for remaining service accounts namely ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto")," and  ",(0,a.kt)("inlineCode",{parentName:"li"},"mmc"),"."),(0,a.kt)("li",{parentName:"ul"},"At the end of this activity, you will have three different service accounts namely  ",(0,a.kt)("inlineCode",{parentName:"li"},"ha "),",  ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto ")," and  ",(0,a.kt)("inlineCode",{parentName:"li"},"mmc "),".")),(0,a.kt)("ol",m({},{start:6}),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Deploy Services:"))),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Navigate to ",(0,a.kt)("inlineCode",{parentName:"li"},"Networking")," tab from side bar."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Services"),"."),(0,a.kt)("li",{parentName:"ul"},"Click on ",(0,a.kt)("inlineCode",{parentName:"li"},"Create Service"),"."),(0,a.kt)("li",{parentName:"ul"},"Copy the content from ",(0,a.kt)("inlineCode",{parentName:"li"},"service_ha.yaml"),"."),(0,a.kt)("li",{parentName:"ul"},"Paste it in the Yaml editor and make sure to change your namespace from ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," to your chosen namespace. (you can leave it as it is if it is default one)."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Create"),"."),(0,a.kt)("li",{parentName:"ul"},"Similarly repeat the steps for  ",(0,a.kt)("inlineCode",{parentName:"li"},"service_mmc.yaml")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"service-statefulset.yaml")," and create two different services."),(0,a.kt)("li",{parentName:"ul"},"At the end of this activity, you will have three different services namely ",(0,a.kt)("inlineCode",{parentName:"li"},"ha")," , ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto"),"  and ",(0,a.kt)("inlineCode",{parentName:"li"},"mmc"),".")),(0,a.kt)("ol",m({},{start:7}),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Deploy Persistent Volume (PV):"))),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Navigate to ",(0,a.kt)("inlineCode",{parentName:"li"},"Storage")," tab from side bar."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"PersistentVolumes"),"."),(0,a.kt)("li",{parentName:"ul"},"Click on ",(0,a.kt)("inlineCode",{parentName:"li"},"Create PersistentVolumes"),"."),(0,a.kt)("li",{parentName:"ul"},"Copy the contents from ",(0,a.kt)("inlineCode",{parentName:"li"},"pv-openshift.yaml"),". Start with copying the PV named ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-pv-0")," ."),(0,a.kt)("li",{parentName:"ul"},"Paste it in the YAML editor and  make sure to change your namespace from ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," to your chosen namespace. (you can leave it as it is if it is default one)."),(0,a.kt)("li",{parentName:"ul"},"Make sure that the path to  ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-2.7-mmc-2.7-cluster-kubernetes-openshift")," folder on your nfs folder is correct. Default configuration expects the folder to be at ",(0,a.kt)("inlineCode",{parentName:"li"},"/root "),"."),(0,a.kt)("li",{parentName:"ul"},"Change the NFS server IP to your own NFS IP in each entry of Persistent Volume configuration."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Create"),"."),(0,a.kt)("li",{parentName:"ul"},"Repeat the steps for creating remaining PVs:  ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-pv-1"),",",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-pv-2"),",",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-pv-3"),",",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-pv-4"),",",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-pv-5")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"mmc-pv"))),(0,a.kt)("ol",m({},{start:8}),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Deploy Persistent Volume Claims (PVCs):"))),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Navigate to ",(0,a.kt)("inlineCode",{parentName:"li"},"Storage")," tab from side bar."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"PersistentVolumeClaim"),"."),(0,a.kt)("li",{parentName:"ul"},"Click on ",(0,a.kt)("inlineCode",{parentName:"li"},"Create PersistentVolumeClaim"),"."),(0,a.kt)("li",{parentName:"ul"},"Copy the contents from ",(0,a.kt)("inlineCode",{parentName:"li"},"pvc-openshift.yaml")," . Start with copying the PVC named ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-data-mosquitto-0"),"."),(0,a.kt)("li",{parentName:"ul"},"Paste it in the YAML editor and  make sure to change your namespace from ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," to your chosen namespace. (you can leave it as it is if it is default one)"),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Create"),"."),(0,a.kt)("li",{parentName:"ul"},"Repeat the steps for creating remaining PVCs:  ",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-data-mosquitto-1"),",",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-data-mosquitto-2"),",",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-data-mosquitto-3"),",",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-data-mosquitto-4"),",",(0,a.kt)("inlineCode",{parentName:"li"},"mosquitto-data-mosquitto-5")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"mmc-config"))),(0,a.kt)("ol",m({},{start:9}),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Deploy Mosquitto (Statefulset):"))),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Navigate to ",(0,a.kt)("inlineCode",{parentName:"li"},"Workloads")," tab from side bar."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"StatefulSets"),"."),(0,a.kt)("li",{parentName:"ul"},"Click on ",(0,a.kt)("inlineCode",{parentName:"li"},"Create StatefulSet"),"."),(0,a.kt)("li",{parentName:"ul"},"Copy the contents from ",(0,a.kt)("inlineCode",{parentName:"li"},"statefulset-openshift.yaml"),","),(0,a.kt)("li",{parentName:"ul"},"Paste it in the YAML editor and make sure to change your namespace from ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," to your chosen namespace. (you can leave it as it is if it is default one)."),(0,a.kt)("li",{parentName:"ul"},"Set the field ",(0,a.kt)("inlineCode",{parentName:"li"},"runAsUser")," to the your own user id. Default one is set to  ",(0,a.kt)("inlineCode",{parentName:"li"},"1000710000"),". You can find the user id of your namespace through the following command: ",(0,a.kt)("inlineCode",{parentName:"li"},"oc describe namespace multinode"),". Refer NFS-Server section for more details."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Create"),".  After this activity, you would see statefulset pods scaling from 0 to 3.")),(0,a.kt)("ol",m({},{start:10}),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Deploy MMC (Deployment):"))),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Navigate to ",(0,a.kt)("inlineCode",{parentName:"li"},"Workloads")," tab from side bar,"),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Deployments")),(0,a.kt)("li",{parentName:"ul"},"Click on ",(0,a.kt)("inlineCode",{parentName:"li"},"Create Deployment"),"."),(0,a.kt)("li",{parentName:"ul"},"Copy the contents from ",(0,a.kt)("inlineCode",{parentName:"li"},"deployment-mmc-openshift.yaml"),","),(0,a.kt)("li",{parentName:"ul"},"Paste it in the YAML editor and make sure to change your namespace from ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," to your chosen namespace. (you can leave it as it is if it is default one)."),(0,a.kt)("li",{parentName:"ul"},"As MMC pod has node affinity , set the value of the field ",(0,a.kt)("inlineCode",{parentName:"li"},"kubernetes.io/hostname")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"value")," field under ",(0,a.kt)("inlineCode",{parentName:"li"},"nodeAffinity")," to the worker node hostname of where you want  MMC pod to spin up. Default value is set to ",(0,a.kt)("inlineCode",{parentName:"li"},"openshift-test-rcjp5-worker-0"),"."),(0,a.kt)("li",{parentName:"ul"},"Set the field ",(0,a.kt)("inlineCode",{parentName:"li"},"runAsUser")," to the your own user id. Default one is set to  ",(0,a.kt)("inlineCode",{parentName:"li"},"1000710000"),". You can find the user id of your namespace through the following command: ",(0,a.kt)("inlineCode",{parentName:"li"},"oc describe namespace multinode"),"."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Create"),".")),(0,a.kt)("ol",m({},{start:11}),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("strong",{parentName:"li"},"Deploy HAProxy (Deployment):"))),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Navigate to ",(0,a.kt)("inlineCode",{parentName:"li"},"Workloads")," tab from side bar."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Deployments"),"."),(0,a.kt)("li",{parentName:"ul"},"Click on ",(0,a.kt)("inlineCode",{parentName:"li"},"Create Deployment"),"."),(0,a.kt)("li",{parentName:"ul"},"Copy the contents from ",(0,a.kt)("inlineCode",{parentName:"li"},"deployment-ha-openshift.yaml"),"."),(0,a.kt)("li",{parentName:"ul"},"Paste it in the YAML editor and make sure to change your namespace from ",(0,a.kt)("inlineCode",{parentName:"li"},"multinode")," to your chosen namespace. (you can leave it as it is if it is default one)."),(0,a.kt)("li",{parentName:"ul"},"Click ",(0,a.kt)("inlineCode",{parentName:"li"},"Create"),".")),(0,a.kt)("h2",m({},{id:"usage"}),"Usage"),(0,a.kt)("p",null,"Once the installation is complete, you can start using the multi-node Mosquitto broker. Be sure to check the Mosquitto documentation for further details on configuring and using the broker"))}g.isMDXComponent=!0},1515:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/okd-infrastructure-1-bba8c29af6e08db7c6f3e61d79bfd615.png"},82081:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/okd-infrastructure-2-abe5236cfef5147cd3d552b6886cc976.png"}}]);